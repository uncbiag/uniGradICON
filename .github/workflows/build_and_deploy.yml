name: Build and Deploy

on:
  push:
    branches:
      - release
      - Add_build_workflow
  workflow_dispatch:
    # Manual trigger with optional inputs if needed
    # inputs:
    #   reason:
    #     description: 'Reason for manual build'
    #     required: false
    #     default: 'Manual testing'

# Add permissions that restrict who can run this workflow
permissions:
  contents: read

jobs:
  # Add a check job that verifies organization membership
  check-membership:
    runs-on: [self-hosted, linux]
    if: github.event_name == 'workflow_dispatch'
    steps:
      - name: Check organization membership
        uses: actions/github-script@v6
        with:
          script: |
            try {
              const isOrgMember = await github.rest.orgs.checkMembershipForUser({
                org: 'uncbiag',
                username: context.actor
              });
              if (isOrgMember.status !== 204) {
                core.setFailed('Only members of uncbiag organization can manually trigger this workflow');
                process.exit(1);
              }
            } catch (error) {
              core.setFailed('Only members of uncbiag organization can manually trigger this workflow');
              process.exit(1);
            }

  build-and-deploy:
    runs-on: [self-hosted, linux]
    needs: [check-membership]
    if: always() && (github.event_name != 'workflow_dispatch' || success())
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
        with:
          ref: Add_build_workflow

      - name: Set up Python 3.8
        uses: actions/setup-python@v2
        with:
          python-version: 3.8

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install build twine pytest

      - name: Build package
        run: python -m build
          
      - name: Get package name and version
        id: pkg_info
        run: |
          # Extract package name and version from setup.cfg
          PKG_NAME=$(grep -m 1 "name = " setup.cfg | cut -d "=" -f 2 | tr -d '[:space:]')
          PKG_VERSION=$(grep -m 1 "version = " setup.cfg | cut -d "=" -f 2 | tr -d '[:space:]')
          echo "pkg_name=$PKG_NAME" >> $GITHUB_OUTPUT
          echo "pkg_version=$PKG_VERSION" >> $GITHUB_OUTPUT
      
      - name: Install package from local build
        run: |
          # Find and install the wheel file
          WHEEL_FILE=$(find dist -name "*.whl" | head -n 1)
          python -m pip install $WHEEL_FILE

      - name: Install dependencies
        run: |
          wget https://www.hgreer.com/assets/slicer_mirror/RegLib_C01_1.nrrd
          wget https://www.hgreer.com/assets/slicer_mirror/RegLib_C01_2.nrrd
          wget https://www.hgreer.com/assets/RegLib_C01_1_foreground_mask.nii.gz
      
      - name: Find idle GPU
        id: find_gpu
        run: |
          # Install nvidia-smi if not available
          if ! command -v nvidia-smi &> /dev/null; then
            echo "nvidia-smi not found, assuming no GPUs available"
            echo "gpu_id=-1" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          # Define minimum required memory in MiB
          MIN_REQUIRED_MEMORY=10000
          
          # Get GPU utilization, memory used and total memory
          echo "Querying available GPUs..."
          GPU_INFO=$(nvidia-smi --query-gpu=index,utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits)
          
          # Count the number of GPUs detected
          GPU_COUNT=$(echo "$GPU_INFO" | wc -l)
          echo "Detected $GPU_COUNT GPU(s)"
          
          # Find the most idle GPU with enough memory
          IDLE_GPU=-1
          LOWEST_SCORE=100000  # Start with a high number
          
          echo "Available GPUs (raw data):"
          echo "$GPU_INFO"
          
          echo "Analyzing each GPU for availability:"
          
          # Process the GPU info line by line - make sure the iteration works properly
          echo "$GPU_INFO" | while IFS="," read -r idx util mem_used mem_total; do
            # Remove leading/trailing spaces
            idx=$(echo $idx | xargs)
            util=$(echo $util | xargs)
            mem_used=$(echo $mem_used | xargs)
            mem_total=$(echo $mem_total | xargs)
            
            # Calculate available memory
            mem_avail=$((mem_total - mem_used))
            
            echo "GPU $idx: Utilization=$util%, Memory=${mem_used}/${mem_total} MiB, Available=${mem_avail} MiB"
            
            # Skip GPU if it doesn't have enough available memory
            if [ $mem_avail -lt $MIN_REQUIRED_MEMORY ]; then
              echo "  - Skipping GPU $idx: insufficient available memory ($mem_avail < $MIN_REQUIRED_MEMORY MiB)"
              continue
            fi
            
            # Calculate a "busy score" (utilization + memory_used/total_memory*100)
            MEMORY_PERCENT=$((mem_used * 100 / mem_total))
            SCORE=$((util + MEMORY_PERCENT))
            
            echo "  - GPU $idx Score=$SCORE (util=$util%, memory_usage=$MEMORY_PERCENT%)"
            
            # Check if this GPU is more idle than previous best
            if [ $SCORE -lt $LOWEST_SCORE ]; then
              LOWEST_SCORE=$SCORE
              IDLE_GPU=$idx
              echo "  - New best GPU: $IDLE_GPU (Score: $LOWEST_SCORE)"
            fi
          done
          
          # Issue: Variables set in pipeline are lost after pipeline completes
          # Fix: Re-detect the best GPU after the while loop
          
          # Re-analyze to get the best GPU
          IDLE_GPU=-1
          LOWEST_SCORE=100000
          
          while IFS="," read -r idx util mem_used mem_total; do
            # Remove leading/trailing spaces
            idx=$(echo $idx | xargs)
            util=$(echo $util | xargs)
            mem_used=$(echo $mem_used | xargs)
            mem_total=$(echo $mem_total | xargs)
            
            # Calculate available memory
            mem_avail=$((mem_total - mem_used))
            
            # Skip if insufficient memory
            if [ $mem_avail -lt $MIN_REQUIRED_MEMORY ]; then
              continue
            fi
            
            # Calculate score
            MEMORY_PERCENT=$((mem_used * 100 / mem_total))
            SCORE=$((util + MEMORY_PERCENT))
            
            # Update if better
            if [ $SCORE -lt $LOWEST_SCORE ]; then
              LOWEST_SCORE=$SCORE
              IDLE_GPU=$idx
            fi
          done <<< "$GPU_INFO"
          
          if [ "$IDLE_GPU" = "-1" ]; then
            echo "No GPU with sufficient memory found"
          else
            echo "Final selection: GPU $IDLE_GPU with score $LOWEST_SCORE"
          fi
          
          echo "gpu_id=$IDLE_GPU" >> $GITHUB_OUTPUT
        
      - name: Run unit tests with GPU
        env:
          CUDA_VISIBLE_DEVICES: ${{ steps.find_gpu.outputs.gpu_id }}
        run: |
          if [ "$CUDA_VISIBLE_DEVICES" == "-1" ]; then
            echo "No GPU available, skipping GPU tests"
          else
            echo "Running tests on GPU $CUDA_VISIBLE_DEVICES"
            python -m unittest discover
          fi

      - name: Test CLI with CPU
        env:
          CUDA_VISIBLE_DEVICES: ""  # Force CPU execution
        run: |
          echo "Running all tests on CPU"
          
          # All commands running on CPU
          unigradicon-register --fixed=RegLib_C01_2.nrrd --fixed_modality=mri --moving=RegLib_C01_1.nrrd --moving_modality=mri \
              --transform_out=trans.hdf5 --warped_moving_out=warped_C01_1.nrrd --io_iterations=None
              
          unigradicon-register --fixed=RegLib_C01_2.nrrd --fixed_modality=mri --moving=RegLib_C01_1.nrrd --moving_modality=mri \
              --transform_out=trans.hdf5 --warped_moving_out=warped_C01_1.nrrd --io_iterations=3
              
          unigradicon-warp --fixed=RegLib_C01_2.nrrd --moving=RegLib_C01_1.nrrd \
              --transform=trans.hdf5 --warped_moving_out=warped_2_C01_1.nrrd --nearest_neighbor
              
          unigradicon-warp --fixed=RegLib_C01_2.nrrd --moving=RegLib_C01_1_foreground_mask.nii.gz \
              --transform=trans.hdf5 --warped_moving_out=warped_2_C01_1.nrrd --nearest_neighbor
              
          unigradicon-jacobian --fixed=RegLib_C01_2.nrrd --transform=trans.hdf5 --jacob=jacobian.nii.gz
      
      # - name: Upload to TestPyPI
      #   env:
      #     TWINE_USERNAME: ${{ secrets.TEST_PYPI_USERNAME }}
      #     TWINE_PASSWORD: ${{ secrets.TEST_PYPI_PASSWORD }}
      #   run: |
      #     python -m twine upload --repository testpypi dist/*
      
      # - name: Uninstall local package
      #   run: |
      #     python -m pip uninstall -y ${{ steps.pkg_info.outputs.pkg_name }}
      
      # - name: Install package from TestPyPI
      #   run: |
      #     python -m pip install --index-url https://test.pypi.org/simple/ --no-deps ${{ steps.pkg_info.outputs.pkg_name }}==${{ steps.pkg_info.outputs.pkg_version }}
      #     # Install dependencies from PyPI (not TestPyPI)
      #     python -m pip install ${{ steps.pkg_info.outputs.pkg_name }}==${{ steps.pkg_info.outputs.pkg_version }} --no-index --find-links dist/

      # - name: Run verification test from TestPyPI installation
      #   run: |
      #     unigradicon-register --fixed=RegLib_C01_2.nrrd --fixed_modality=mri --moving=RegLib_C01_1.nrrd --moving_modality=mri \
      #         --transform_out=trans_testpypi.hdf5 --warped_moving_out=warped_testpypi.nrrd --io_iterations=None
      
      # - name: Upload to PyPI
      #   env:
      #     TWINE_USERNAME: ${{ secrets.PYPI_USERNAME }}
      #     TWINE_PASSWORD: ${{ secrets.PYPI_PASSWORD }}
      #   run: |
      #     python -m twine upload dist/*
      
      - name: Upload distributions
        uses: actions/upload-artifact@v4
        with:
          name: release-dists
          path: dist/